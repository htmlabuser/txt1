<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>001</title>
</head>
<body>

AWS Glue Data Quality allows you to measure and monitor the quality of your data so that you can make good business decisions.
<br>
Built on top of the open-source DeeQu framework, AWS Glue Data Quality provides a managed, serverless experience. AWS Glue Data Quality works with Data Quality Definition Language (DQDL), which is a domain specific language that you use to define data quality rules.
<br>
To learn more about DQDL and supported rule types, see Data Quality Definition Language (DQDL) reference: https://docs.aws.amazon.com/glue/latest/dg/dqdl.html
<br>
For additional product details and pricing, see the service page for AWS Glue Data Quality: http://aws.amazon.com/glue/features/data-quality
<br>
Benefits and key features
<br>
Serverless – there is no installation, patching or maintenance.
<br>
Get started quickly – AWS Glue Data Quality quickly analyzes your data and creates data quality rules for you. You can get started with two clicks: “Create Data Quality Rules → Recommend rules”.
<br>
Improvise your rules – with 25+ out-of-the-box DQ rules to start from, you can create rules that suit your specific needs.
<br>
Evaluate quality and make confident business decisions – Once you evaluate the rules, you get a Data Quality score that provides an overview of the health of your data. Use Data Quality score to make confident business decisions.
<br>
Zero in on bad data – AWS Glue Data Quality helps you identify the exact records that caused your quality scores to go down. Easily identify them, quarantine and fix them.
<br>
Pay as you go – There are no annual licenses you need to use AWS Glue Data Quality
<br>
No lock-in – AWS Glue Data Quality is built on open source DeeQu, allowing you to keep the rules you are authoring in an open language.
<br>
Data quality checks – AWS Glue Data Quality You can enforce data quality checks on Data Catalog and AWS Glue ETL pipelines allowing you to manage data quality at rest and in transit.
<br>
How it works
<br>
There are two entry points for AWS Glue Data Quality: the AWS Glue Data Catalog and AWS Glue ETL jobs. This section provides an overview of the use cases and AWS Glue features that each entry point supports.
<br>
Data quality for the AWS Glue Data Catalog
<br>
AWS Glue Data Quality evaluates objects that are stored in the AWS Glue Data Catalog It offers non-coders an easy way to set up data quality rules.
<br>
These personas include data stewards and business analysts.
<br>
You might choose this option for the following use cases:
<br>
You want to perform data quality tasks on data sets that you've already cataloged in the AWS Glue Data Catalog.
<br>
You work on data governance and need to identify or evaluate data quality issues in your data lake on an ongoing basis.
<br>
You can manage data quality for the Data Catalog using the following interfaces:
<br>
The AWS Glue management console
<br>
AWS Glue APIs
<br>
To get started with AWS Glue Data Quality for the AWS Glue Data Catalog see Getting started with AWS Glue Data Quality for the Data Catalog: https://docs.aws.amazon.com/glue/latest/dg/data-quality-getting-started.html
<br>
Data quality for AWS Glue ETL jobs
<br>
AWS Glue Data Quality for AWS Glue ETL jobs lets you perform proactive data quality tasks. Proactive tasks help you identify and filter out bad data before you load a data set into your data lake.
<br>
You might choose data quality for ETL jobs for the following use cases:
<br>
You want to incorporate data quality tasks into your ETL jobs
<br>
You want to write code that defines data quality tasks in ETL scripts
<br>
You want to manage the quality of data that flows in your visual data pipelines
<br>
You can manage data quality for ETL jobs using the following interfaces:
<br>
AWS Glue Studio, AWS Glue Studio notebooks, and AWS Glue interactive sessions
<br>
AWS Glue libraries for ETL scripting
<br>
AWS Glue APIs
<br>
To get started with data quality for ETL jobs, see Tutorial: Getting started with Data Quality in the AWS Glue Studio User Guide: https://docs.aws.amazon.com/glue/latest/ug/gs-data-quality-chapter.html
<br>
Comparing data quality for the Data Catalog to data quality for ETL jobs
<br>
This table provides an overview of features that each entry point for AWS Glue Data Quality supports.
<br>
Table (divider '|'):
Feature | Data quality for the Data Catalog | Data quality for ETL jobs
Data sources | Amazon S3, Amazon Redshift, JDBC sources compatible with the Data Catalog, and transactional data lake formats such as Apache Iceberg, Apache Hudi, and Delta Lake. | All data sources supported by AWS Glue, including custom connectors and third-party connectors.
Data Quality rule recommendations | Supported | Not supported
Author and run DQDL rules | Supported | Supported
Auto scaling | Not supported | Supported
AWS Glue Flex support | Not supported | Supported
Scheduling | Supported when evaluating Data Quality rules and via Step Functions. | Supported when using Step Functions and workflows.
Identifying records that failed data quality checks | Not supported | Supported
Integration with Amazon Eventbridge | Supported | Supported
Integration with AWS Cloudwatch | Supported | Supported
Writing data quality results to Amazon S3 | Supported | Supported
Incremental data quality | Supported via pushdown predicates | Supported via AWS Glue bookmarks
AWS CloudFormation support | Supported | Supported
<br>
Considerations
<br>
Consider the following items before you use AWS Glue Data Quality: Data quality rules can't evaluate nested or list-type data sources.
<br>
Release notes for AWS Glue Data Quality
<br>
This topic describes features introduced in AWS Glue Data Quality.
<br>
General availability: new features
<br>
The following new features are available with the general availability of AWS Glue Data Quality:
<br>
The ability to identify which records failed data quality checks is now supported in AWS Glue Studio
<br>
New data quality ruletypes such as validating referential integrity of data between two data sets, comparing data between two datasets, and data type checks
<br>
Improved user experience in the AWS Glue Data Catalog
<br>
Support for Apache Iceberg, Apache Hudi and Delta Lake
<br>
Support for Amazon Redshift
<br>
Simplified notification with Amazon Eventbridge
<br>
AWS CloudFormation support for creating rulesets
<br>
Performance improvements: caching option in ETL and AWS Glue Studio for faster performance when evaluating data quality

</body>
</html>
